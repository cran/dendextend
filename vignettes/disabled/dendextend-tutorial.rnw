<<eval=FALSE, echo=FALSE>>=
toBibtex(citation("dendroextras"))
toBibtex(citation("labeltodendro",auto=TRUE))
toBibtex(citation("Heatplus"))
toBibtex(citation("latticeExtra"))
toBibtex(citation("bclust"))
toBibtex(citation("sparcl"))
toBibtex(citation("ggdendro"))
toBibtex(citation("ape"))
toBibtex(citation("Rcpp"))
toBibtex(citation("boot"))
toBibtex(citation("profdpm"))
toBibtex(citation("dendextendRcpp"))
toBibtex(citation("microbenchmark"))
toBibtex(citation("gplots"))


toBibtex(packageDescription("stats"))

toBibtex(citation("DendSer"))
@

%% need no \usepackage{Sweave.sty}

<<prelim,echo=FALSE, cache=FALSE>>=
suppressPackageStartupMessages(library(dendextend))
dendextend.version <- packageDescription("dendextend")$Version
dendextend.date <- packageDescription("dendextend")$Date
now.date <- strftime(Sys.Date(), "%B %d, %Y")
# options(width = 60)
# opts_chunk$set(tidy.opts=list(width.cutoff=60))
opts_chunk <- knitr:::opts_chunk
opts_chunk$set( fig.align='center', cache=TRUE) # , message=FALSE, background='white')
options(replace.assign=TRUE,width=60)

# knit_hooks$set(fig=function(before, options, envir){if (before) par(mar=c(4,4,.1,.1),cex.lab=.95,cex.axis=.9,mgp=c(2,.7,0),tcl=-.3)})

@
%




%% use JSS class -- use 'nojss' to turn off header
\documentclass[shortnames,nojss,article]{jss}
\usepackage{booktabs,flafter,thumbpdf}
%\VignetteIndexEntry{An Introduction to dendextend}
%\VignetteKeywords{Dendrogram, hclust, heirarchical clustering, visualization, tanglegram, R}
%\VignettePackage{dendextend}
%\VignetteEngine{knitr::knitr}
\usepackage[utf8]{inputenc}


\Plaintitle{Visualizing and Comparing Trees of Hierarchical Clustering: Using the dendextend R Package}
\title{Visualizing and Comparing \\ Trees of Hierarchical Clustering: \\ Using the dendextend \proglang{R} Package}


% \Plaintitle{Manipulate, Visualize and Compare Dendrograms: The dendextend R Package}
% \title{Manipulate, Visualize and Compare Dendrograms:\\ The \pkg{dendextend} \proglang{R} Package}


% \author{Tal Galili\\Tel-Aviv University \And Yoav Benjamini\\Tel-Aviv University}
% \Plainauthor{Tal Galili, Yoav Benjamini}

\author{Tal Galili\\Tel-Aviv University}
\Plainauthor{Tal Galili}



\Abstract{

A dendrogram is a tree diagram which is often used to visualize an hierarchical clustering of items. Dendrograms are used in many disciplines, ranging from Phylogenetic Trees in computational biology to Lexomic Trees in text analysis.

The \pkg{dendextend} package extends the dendrogram objects in the \proglang{R} programming language, allowing for easy manipulation of a dendrogram's shape, color and content. Furthermore, it provides tools for comparing the similarity of two dendrograms to one another both graphically (using tanglegrams) and statistically (from cophenetic correlations to Bk plots).

The paper gives a detailed exposition of both the internal structure of the package and the provided user interfaces.
}

\Keywords{Dendrogram, hclust, hierarchical clustering, visualization, tanglegram,  \proglang{R}}
\Plainkeywords{Dendrogram, hclust, hierarchical clustering, visualization, tanglegram, R}


% \begin{center} \today \end{center}.

% \Volume{40}
% \Issue{8}
% \Month{April}
% \Year{2011}
% \Submitdate{2010-11-15}
% \Acceptdate{2011-03-21}

\Address{
  Tal Galili \\
   Department of Statistics and Operations Research \\
   Tel Aviv University, Israel \\
   E-mail: \email{Tal.Galili@math.tau.ac.il}\\
   URLs: \url{http://www.R-Statistics.com/}, 
         \url{http://www.R-Bloggers.com/},\\

%   Yoav Benjamini\\
%    The Nathan and Lily Silver\\
%    Professor of Applied Statistics\\
%    Department of Statistics and Operations Research \\
%    Tel Aviv University, Israel \\
%    E-mail: \email{ybenja@tau.ac.il}\\
%    URL: \url{http://www.tau.ac.il/~ybenja/}
}



\begin{document}
\vspace*{-0.25cm}

%% Doesn't seem to work:
%% \tableofcontents


\section{Introduction}

\subsection{The \code{dendrogram} object}

The \code{dendrogram} class provides general functions for handling tree-like structures in \proglang{R} \citep{R:Main}. It is intended as a replacement for similar functions in hierarchical clustering and classification/regression trees, such that all of these can use the same engine for plotting or cutting trees.

A dendrogram object represents a tree as a nested \code{list} object, with various attributes.

Dendrogram has several useful methods bundled with R:

<<>>=
methods(class="dendrogram")
@

For example, let's create a dendrogram object based on an hierarchical clustering of 4 states in the U.S.:

<<>>=
# our data:
data(USArrests)
US_data <- USArrests[c(2,5,32,35),]
print(US_data)

hc <- hclust(dist(US_data), "ave") # create an Hierarchical clustering object
dend <- as.dendrogram(hc)
@


Below are examples for some dendrogram methods:

<<out.width="4in", out.height="4in",fig.align='center'>>=
print(dend)
labels(dend)
str(dend)
str(dend[[2]]) # looking at one branch of the dendrogram
plot(dend)
@

You might notice how the order of the items (leaves/terminal nodes) of the dendrogram is different than their order in the original table of data. We can re-order the rows in the table to have the same order as the items in the dendrogram, with the \code{order.dendrogram} function:

<<>>=
(new_order <- order.dendrogram(dend)) 
# the order of the original items to have them 
# be at the same order as they assume in the dendrogram
print(US_data[new_order,])
@


In order to see what our dendrogram (\code{list}) object includes, we need to use the \code{unclass} function, which will strip away the class attribute and will allow us to print the list as is, without going through the \code{print.dendrogram} method. We can see how each node in the dendrogram/list object has the following (self explaining) attributes:

<<>>=
str(unclass(dend))
@


Notice how terminal nodes uses the "leaf" attribute (set to TRUE).
<<>>=
names(attributes(dend)[-4])
@



A very important function is \code{dendrapply}. It applies some function recursively to each node of a dendrogram. It is often used for adjusting attributes of the object, or extracting something from it. 

One current "feature" with this function is that just sending a dendrogram through it will return it with each of its nodes becoming of class "dendrogram". This can lead to trouble when comparing the output of running the functiion with the original object. This can be resolved using the \code{unclass_dend} function. For example:

<<>>=
# dendrapply(dend, unclass) # in case the  
itself <- function(x) x
dend_from_dendrapply <- dendrapply(dend, itself)

identical(dend, dend_from_dendrapply)

# here we must first use unclass since the output of "[[]]" inherits its class from the original object's class:
class(unclass(dend)[[2]])
class(unclass(dend_from_dendrapply)[[2]])
class(unclass_dend(dend_from_dendrapply)[[2]]) # the new uncless_dend solves it.
@



\subsection{Motivation for creating \code{dendextend}}



The \code{dendrogram} object has several \textbf{advantages}:

\begin{enumerate}

   \item \code{dendrogram} objects are nested list of lists (with attributes). This makes their structure familiar and easy to understand by R users. They are also, relatively, simple to manipulate, extend and connect to different packages.
   \item \code{dendrogram} objects have various methods and functions for using them within R base. 
   \item Other tree objects, such as \code{hclust}, and objects from the \pkg{ape} package \citep{CRAN:ape},  include an \code{as.dendrogram} method for converting their objects into a dendrogram. And also \code{as.phylo.dendrogram}, \code{as.hclust.dendrogram}.
   \item \code{dendrogram} objects are used in various packages as an intermediate step for other purposes (often plotting), such as:
   
   \begin{enumerate}
   \item The \pkg{latticeExtra} package \citep{CRAN:latticeExtra}, see the \code{dendrogramGrob} function.
   \item The \pkg{labeltodendro} package \citep{CRAN:labeltodendro}, see the \code{colorplot} function.
   \item The \pkg{bclust} package \citep{CRAN:bclust}, see the \code{bclust} function.
   \item The \pkg{ggdendro} package \citep{CRAN:ggdendro}, see the \code{dendro_data} function.
   \item The \pkg{gplots} package \citep{CRAN:gplots}, see the \code{heatmap.2} function.
   \item The \pkg{Heatplus} package \citep{CRAN:Heatplus}, see the \code{annHeatmap2} function.
   \item The \pkg{sparcl} package \citep{CRAN:Heatplus}, see the \code{ColorDendrogram} function.
   \end{enumerate}
   
\end{enumerate}
   
   %\pkg{DendSer} (see the \code{} function), 


However, even with all of its advantages, the \code{dendrogram} class in R still lacks various basic features.

The \code{dendextend} package aims at filling some gaps in base R, by extending the available functions for dendrogram manipulation, statistical analysis, and visualization.

This vignettes gives a step-by-step description of the functionality available in the \code{dendextend} package.


\subsection{Installing \code{dendextend}}

To install the stable version from CRAN use:

<<eval=FALSE>>=
install.packages('dendextend') # not yet available from CRAN
@


To install the \href{https://github.com/talgalili/dendextend}{GitHub version} use:

<<eval=FALSE>>=
if (!require('devtools')) install.packages('devtools'); require('devtools')
install_github('dendextend', 'talgalili')
@


\section{Tree attributes (extraction, assignment, length)}


\subsection{labels in base R}

In base R, the \code{labels} function is intended to find/extract a suitable set of labels from an object for use in printing or plotting, for example. By default, it uses the \code{names} and \code{dimnames} functions.

What base R \code{labels} function is missing is assignment. In the next few examples we will go through different examples of what the \code{dendextend} package offers for various objects.

\textbf{Credits:} These assignment functions were originally written by Gavin Simpson (in a post on \href{http://stackoverflow.com/questions/4614223/how-to-have-the-following-work-labelsx-some-value-r-question}{(stackoverflow)}), and adopted/adjusted to this package by Tal Galili. Some modification were inspired by Gregory Jefferis's code from the \pkg{dendroextras} package.


\subsection{labels for vectors and matrices}

In base R, for vectors, labels gives the \code{names} of the object. And if these are missing, then \code{labels} will give the vector itself as a character vector:

<<>>=
x <- 1:3 
names(x) # this vector has no names
labels(x) # this vector has no labels
@

Assignment to names is available in base R and works as follows:

<<>>=
x <- 1:3 
names(x) <- letters[1:3] # assignment for names is in base R
#both names and labels will give the same result:
names(x) 
labels(x)

@


The new labels assignment function will allow a user to change the content of the vector's "labels" (similar to what can be done using "names"):

<<>>=
x <- 1:3 
labels(x) <- letters[1:3]
names(x) 
labels(x)
@

Labels assignment are also available for matrices.


\subsection{labels for dendrogram objects}

We can get a dendrogram's labels using the \code{labels} function from base R. However, in order to assign new values to it, we'll need the assignment function from \pkg{dendextend}:

<<>>=
labels(dend) # from base R
labels(dend) <- c("OH", "AK", "CA", "NY") # labels assingment - thanks to dendextend
labels(dend)
@


\subsection{labels for hclust objects}

\pkg{dendextend} offers a \code{labels} method for \code{hclust} objects. It take special care to have the order of the labels be the same as is with dendrogram object, which is the order of the labels in the plotted tree. This can be turned off when using the \code{order} parameter:

<<>>=
# All are from dendextend
labels(hc) 
labels(hc,order=FALSE) # this is the order of the rows of the original data.
set.seed(229835)
labels(hc) <- sample(labels(hc)) # labels assingment - thanks to dendextend
labels(hc)
@


\subsection{labels assignment and recycling}

When the assigned vector has a different length, the \pkg{dendextend} assignment functions will recycle the value but also give a warning:

<<>>=

x <- 1:3   
hc <- hclust(dist(US_data), "ave")
dend <- as.dendrogram(hc)
y <- matrix(1:9, 3,3)   

labels(x) <- "bob"
labels(x)
labels(hc) <- "bob"
labels(hc)
labels(dend) <- "bob"
labels(dend)
labels(y) <- "bob"
labels(y)

@


\subsection{Tree size - number of leaves}

Getting the size of a tree (e.g: number of leaves/terminal-nodes) is good for validation of functions, and also when we wish to initiate a variable to later fill with data from the leaves. 

The \code{labels} function for dendrogram is expensive, since it uses recursion to get all of the tree's elements. If we are only interested in getting the tree size, it is better to use the \code{nleaves} function. It has an S3 method for hclust, dendrogram and phylo (from the \pkg{ape}):

<<>>=
nleaves(hc)
nleaves(dend)
@

For dendrograms the speed improvement is about 10 times using \code{labels}, whereas for hclust, there is not any gain made by using \code{nleaves}. Here is a quick benchmark:

<<cache=TRUE>>=
library(microbenchmark)
microbenchmark(nleaves(dend), length(labels(dend)))
microbenchmark(nleaves(hc), length(labels(hc)))
@

There are border-line cases where the node above some leaves is of height 0. In such a case, we would consider that node as a "terminal node", and in order to count the number of such terminal nodes we would use \code{count_terminal_nodes} function. For example:

<<fig.height = 3,fig.align='center'>>=

hc <- hclust(dist(USArrests[1:3,]), "ave")
dend <- as.dendrogram(hc)

par(mfrow = c(1,2))

###
# Trivial case
count_terminal_nodes(dend) # 3 terminal nodes
length(labels(dend)) # 3 - the same number
plot(dend, 
   main = "This is considered a tree \n with THREE terminal nodes") 

###
# NON-Trivial case
str(dend)
attr(dend[[2]], "height") <- 0
count_terminal_nodes(dend) # 2 terminal nodes, why? see this plot:
# while we have 3 leaves, in practice we have only 2 terminal nodes
# (this is a feature, not a bug.)
plot(dend,
   main = "This is considered a tree \n with TWO terminal nodes only") 

@


\subsection{Tree size - number of nodes}

Getting the size of a tree, in terms of the number of nodes can easily be done using:

<<>>=
hc <- hclust(dist(USArrests[1:3,]), "ave")
dend <- as.dendrogram(hc)

nnodes(hc)
nnodes(dend)
@



\subsection{Generally getting tree attributes}

Getting tree attributes can more generally be achieved using \code{get_nodes_attr}, however, the dedicated function are often faster than the general solution. (also, in the future, we might introduce functions based on \pkg{Rcpp}, offering even faster times).

Here are some examples:

<<>>=
hc <- hclust(dist(USArrests[1:3,]), "ave")
dend <- as.dendrogram(hc)

# get_leaves_attr(dend) # error :)
get_leaves_attr(dend, "label")
labels(dend, "label")

get_leaves_attr(dend, "height") # should be 0's
get_nodes_attr(dend, "height") 
get_branches_heights(dend, sort = FALSE) # notice the sort=FALSE


get_leaves_attr(dend, "leaf") # should be TRUE's
get_nodes_attr(dend, "leaf") # conatins NA's
get_nodes_attr(dend, "leaf", na.rm = TRUE) # 


get_leaves_attr(dend, "members") # should be 1's
get_nodes_attr(dend, "members", include_branches = FALSE, na.rm = TRUE) # 
get_nodes_attr(dend, "members") # 
get_nodes_attr(dend, "members", include_leaves = FALSE, na.rm = TRUE) # 


hang_dend <- hang.dendrogram(dend)
get_leaves_attr(hang_dend, "height") # no longer 0!
get_nodes_attr(hang_dend, "height") # does not include any 0s!

# does not include leaves values:
get_nodes_attr(hang_dend, "height", include_leaves = FALSE) 
# remove leaves values all together:
get_nodes_attr(hang_dend, "height", include_leaves = FALSE, na.rm = TRUE) 
get_branches_heights(hang_dend) # notice the sort
get_branches_heights(hang_dend, sort = FALSE) # notice the sort


@


Quick comparison on fetching leaves attributes:

<<>>=

library(microbenchmark)
# get_leaves_attr is twice faster than get_nodes_attr
microbenchmark(   get_leaves_attr_4members = get_leaves_attr(dend, "members"), 
                  get_nodes_attr_4members = get_nodes_attr(dend, "members", include_branches = FALSE, na.rm = TRUE)
)



@






\section{Tree manipulation}

\subsection{unbranching and root height}

A tree's nodes have various heights. Sometimes we are interested in changing the height of the entire tree. This can be accomplished using \code{raise.dendrogram}. For example (notice how the entire tree's height is changed):

<<fig.height = 3,fig.align='center'>>=

hc <- hclust(dist(USArrests[1:3,]), "ave")
dend <- as.dendrogram(hc)

taller_dend <- raise.dendrogram(dend, 10)
shorter_dend <- raise.dendrogram(dend, -10)

attr(dend, "height") # 54.80041
attr(taller_dend, "height") # 64.80041
attr(shorter_dend, "height") # 44.80041

par(mfrow = c(1,3))
plot(dend, ylim = c(0, 70), main = "Original dend"); abline(h = c(40, 50, 60), lty = 2)
plot(taller_dend, ylim = c(0, 70), main = "Taller dend"); abline(h = c(40, 50, 60), lty = 2)
plot(shorter_dend, ylim = c(0, 70), main = "Shorter dend"); abline(h = c(40, 50, 60), lty = 2)

@



Sometimes we wish to "unbranch" the dendrogram, meaning that we merge one of the tree's branches with its root. This is useful, for example, when merging phylogenetic trees from several families, and being unwilling to assume a specific root/height to the merged trees. Unbranching can be done using the \code{unbranch} (S3) function (notice the use of the \code{branch_becoming_root} parameter):


<<fig.height = 3,fig.align='center'>>=

hc <- hclust(dist(USArrests[10:13,]), "ward")
dend <- as.dendrogram(hc)

unbranched_dend <- unbranch(dend, branch_becoming_root=1)
unbranched_dend_2 <- unbranch(unbranched_dend, branch_becoming_root=3)

par(mfrow = c(1,3))
plot(dend)
plot(unbranched_dend)
plot(unbranched_dend_2)

@

While the \code{unbranch.hclust} method exists, it is not expected to work since \code{hclust} objects are not designed to handle non-binary trees (hence the advantage of using \code{dendrogram} objects). For \code{phylo} objects (from the \pkg{ape} package), there is also a method that would simply use \code{ape::unbranch(phy = x)}.

In some rare cases, we might wish to equalize the heights of root's branches. For this we can use the \code{flatten.dendrogram} function:


<<fig.height = 3, fig.align='center'>>=

hc <- hclust(dist(USArrests[10:13,]), "ward")
dend <- as.dendrogram(hc)

flatten_dend_1 <- flatten.dendrogram(dend,FUN=max)
flatten_dend_2 <- flatten.dendrogram(dend,FUN=min)

par(mfrow = c(1,3))
plot(dend, main = "Original tree"); abline(h = c(50, 100), lty=2)
plot(flatten_dend_1, main = "Flatten tree \n(max branches height)"); abline(h = c(50, 100), lty=2)
plot(flatten_dend_2, main = "Flatten tree \n(min branches height)"); abline(h = c(50, 100), lty=2)

@




\subsection{Coloring labels of leaves}

Coloring labels can sometimes be useful, it is done through the \code{labels_colors} function (which also has assignment). Notice the assignment recycling, as well as the difference in the appearance of a dot when a label's color is black, compared to when it is NULL:

<<fig.height=3,fig.align='center'>>=

par(mfrow = c(1,3))

hc <- hclust(dist(USArrests[1:3,]), "ave")
dend <- as.dendrogram(hc)

# Defaults:
labels_colors(dend)
plot(dend)

# let's add some color:
library(colorspace)
labels_colors(dend) <- rainbow_hcl(3)
labels_colors(dend)
plot(dend)

# changing color to black
labels_colors(dend) <- 1
labels_colors(dend)
plot(dend)

# removing color (and the nodePar completely - if it has no other attribute but lab.col)
labels_colors(dend) <- NULL
labels_colors(dend)

@




\subsection{Hanging a dendrogram}

Hanging a tree means that we change the height of the leaves to be near their parent node. Hanging helps when examining the topology of the tree. Currently, hanging of a dendrogram was possible by going through the hclust object, but now you can simply use the \code{hang.dendrogram} function. Here is an example:
<<fig.height = 3,fig.align='center'>>=
hc <- hclust(dist(USArrests[1:9,]), "ave")
dend <- as.dendrogram(hc)
hang_dend_1 <- hang.dendrogram(dend, hang = 0.1)
hang_dend_2 <- as.dendrogram(hc, hang = 0.1) # another way of doing it, if 
               #  we could move from/to hclust
identical(hang_dend_1, hang_dend_2) # and they are the same :)

library(colorspace)
labels_colors(hang_dend_1) <- rainbow_hcl(nleaves(hang_dend_1))

par(mfrow = c(1,2))
plot(hc, main ="Hanged hclust tree")
plot(hang_dend_1, main ="Hanged dendrogram tree")
@


\subsection{Trimming leaves}

Trimming some leaves from a tree can be done using the \code{prune} (S3 method) function (notice that the attributes of the pruned tree are updated):

<<fig.height = 3,fig.align='center'>>=

hc <- hclust(dist(USArrests[1:5,]), "ave")
dend <- as.dendrogram(hc)
library(colorspace)
labels_colors(dend) <- rainbow_hcl(5)

pruned_dend <- prune(dend , c("Alaska", "California"))

str(unclass(pruned_dend))

par(mfrow = c(1,2))
plot(dend, main = "Original tree")
plot(pruned_dend, main = "Tree without Alaska/California")

@

If we have two trees, we can use the \code{intersect_trees} function to reduce both trees to have the same labels (this will be useful later when we'd like to compare the two trees):


<<fig.align='center'>>=

hc_1 <- hclust(dist(USArrests[1:5,]), "single")
hc_2 <- hclust(dist(USArrests[1:5,]), "complete")
dend_1 <- as.dendrogram(hc_1)
dend_2 <- as.dendrogram(hc_2)

library(colorspace)
labels_colors(dend_1) <- rainbow_hcl(5)
labels_colors(dend_2) <- rainbow_hcl(5)


pruned_dend_1 <- prune(dend_1 , c("Alaska"))
pruned_dend_2 <- prune(dend_2 , c("California"))

dends_12 <- intersect_trees(pruned_dend_1,pruned_dend_2)

par(mfrow = c(3,2))
plot(dend_1, main = "Tree - single method", ylim = c(0,110))
plot(dend_2, main = "Tree - complete method", ylim = c(0,110))
plot(pruned_dend_1, main = "Trimmed tree - single method", ylim = c(0,110))
plot(pruned_dend_2, main = "Trimmed tree - complete method", ylim = c(0,110))
plot(dends_12[[1]], main = "Intersected tree - single method", ylim = c(0,110))
plot(dends_12[[2]], main = "Intersected tree - complete method", ylim = c(0,110))



@

Side-note: a similar function, called \code{plotColoredClusters}, is available in the \pkg{ClassDiscovery} package for \code{hclust} objects.


\subsection{Rotating branches}

A dendrogram is an object which can be rotated on its hinges without 
changing its topological.

Rotating a dendrogram in base R can be done using the \code{reorder} function.
The problem with this function is that it is not very intuitive. For this reason
we wrote the \code{rotate} function. It has two main arguments: the object, and
the order we wish to rotate it by. The order parameter can be either a numeric
vector, used in a similar way we would order a simple character vector. Or, the
order parameter can also be a character vector of the labels of the tree, given
in the new desired order of the tree.

It is also worth noting that some order are impossible to achieve for a given 
tree's topology. In such a case, the function will do its "best" to get as close
as possible.

Here are a few examples:


<<fig.align='center'>>=

hc <- hclust(dist(USArrests[c(1,6,13,20, 23),]), "ave")
dend <- as.dendrogram(hc)

# For dendrogram objects:
library(colorspace)
labels_colors(dend) <- rainbow_hcl(nleaves(dend)) 
# let's color the labels to make the followup of the rotation easier
par(mfrow = c(2,2))
plot(dend, main = "Original tree") 
plot(rotate(dend, c(2:5,1)), main = 
        "Rotates the left most leaf \n into the right sided of the tree")
plot(dend, main = "Original tree") 
plot(sort(dend), main = "Sorts the labels by alphabetical order \n 
     and rotates the tree to give the best fit possible")
@




\subsection{Cutting trees}

The \code{hclust} function comes with a very powerful \code{cutree} function, for extracting cluster grouping of the original data based on cutting the Hierarchical tree at some height (or setting a predefined k - number of clusters). The limitation of this function is that it is only available for \code{hclust} object. Hence, if we are dealing with a tree which is NOT an ultrametric tree (e.g: ultrametric tree = a tree with monotone clustering heights), \code{cutree} would not be available for us (since \code{as.hclust} would not work on our dendrogram).

In \pkg{dendextend}, we extend \code{cutree} by turning it into an S3 method, with methods for dendrogram and phylo objects. The phylo method is only turning the phylo object to an hclust, and tries to work on it there. However, the dendrogram method (\code{cutree.dendrogram}) is a complete re-writing of \code{cutree} based on the \code{cut.dendrogram} function. \code{cutree.dendrogram} fully emulates \code{cutree} by default, but at the same time extends it with the type of trees it can handle, and with some other options.

Since \code{cutree.dendrogram} is written in \proglang{R}, it is slower than \code{cutree} which is implemented in \proglang{C}. If we can turn the dendrogram into hclust, we will use \code{cutree.hclust}, otherwise - \code{cutree.dendrogram} will be used.

Here are several examples of how these functions are used:

<<cache=TRUE>>=

hc <- hclust(dist(USArrests[c(1,6,13,20, 23),]), "ave")
dend <- as.dendrogram(hc)
unbranch_dend <- unbranch(dend,2)

cutree(hc, k=2:4) # on hclust
cutree(dend, k=2:4) # on dendrogram

cutree(hc, k=2) # on hclust
cutree(dend, k=2) # on dendrogram

cutree(dend, h = c(20, 25.5, 50,170))
cutree(hc, h = c(20, 25.5, 50,170))

# the default (ordered by original data's order)
cutree(dend, k=2:3, order_clusters_as_data = FALSE) 
labels(dend)

# cutree now works for unbranched trees!
# as.hclust(unbranch_dend) # ERROR - can not do this...
cutree(unbranch_dend, k = 2) # all NA's
cutree(unbranch_dend, k = 1:4)
cutree(unbranch_dend, h = c(20, 25.5, 50,170))


library(microbenchmark)
## this shows how as.hclust is expensive - but still worth it if possible
microbenchmark(
   cutree(hc, k=2:4),
   cutree(as.hclust(dend), k=2:4),
   cutree(dend, k=2:4),
   cutree(dend, k=2:4, try_cutree_hclust=FALSE)
)          
# the dendrogram is MUCH slower...


# and trying to "hclust" is not expensive (which is nice...)         
microbenchmark(
   cutree_unbranch_dend = cutree(unbranch_dend, k=2:4, warn = FALSE),
   cutree_unbranch_dend_not_trying_to_hclust = 
      cutree(unbranch_dend, k=2:4, try_cutree_hclust=FALSE, warn = FALSE)
)


@


Having \code{cutree.dendrogram} available to us, we can now gain the ability to color branches for trees which can not be represented as an \code{hclust} object.

\subsection{Coloring branches}


Dendrogram plots with colored branches are used to easily distinguish between different clusters on a tree. They have been available in R for many years in threads on the mailing lists and through various package. However, until recently, all of the functions in packages have always given the user a new \code{plot} function, without separating the coloring of branches of a dendrogram from its plotting. Often the function for actually plotting the colored branched dendrogram would be hidden from the user. For example, the \pkg{labeltodendro} package \citep{CRAN:labeltodendro} gives a colored branch plot through the \code{colorplot} function, but the work horse for this is available in a hidden function called \code{dendroploth} or \code{dendroplotv}, both take care of the plotting by themselves (instead of modifying the dendrogram object, and then letting the base R function do the work). The same story happens in the \pkg{Heatplus} \citep{CRAN:Heatplus}, where the \code{plot.annHeatmap2} function actually uses the hidden function \code{cutplot.dendrogram} for doing the plotting.

This was changed in the beginning of 2013 thanks to Gregory Jefferis's \pkg{dendroextras} package \citep{CRAN:dendroextras}, which organized this through the \code{colour_clusters} function. In the \pkg{dendextend} package we imported his code into a new function called \code{color_branches}, with several useful modifications on the original code. The biggest limitation in the \code{colour_clusters} function is that it relies on changing the \code{dendrogram} into \code{hclust} in order to use \code{cutree} on it and get the clusters. This has the advantage of being fast, but the \textbf{disadvantage} of restricting the function to ultrametric and binary trees (the type of tree \code{hclust} objects can handle). Here we implemented a new function called \code{cutree.dendrogram} (available as an S3 method), which rely on \code{hclust} for speed, but if it is not possible to convert the dendrogram to hclust, it will find the clustering on the dendrogram object itself (while being fully compatible with the base R \code{cutree} function). Also, our implementation of the \code{color_branches} function allows for repeated-multilayered coloring of the branches. Another potential bug which is avoided in our implementation is to handle cases where the labels of the tree are of type Integer instead of Character (this happens if the \code{dendrogram} came from an \code{hclust}, used on the \code{dist} of data that has no \code{rownames}).

Here is an example of using \code{color_branches} combined with \code{labels_colors}:

<<iris_colored_branches, fig.height = 10, fig.width=7 ,fig.align='center'>>=
library(colorspace)

data(iris) 
d_iris <- dist(iris[,-5]) # method="man" # is a bit better
hc_iris <- hclust(d_iris)
labels(hc_iris) # no labels, because "iris" has no row names
dend_iris <- as.dendrogram(hc_iris)
is.integer(labels(dend_iris)) # this could cause problems...

iris_species <- rev(levels(iris[,5]))
dend_iris <- color_branches(dend_iris,k=3, groupLabels=iris_species)
is.character(labels(dend_iris)) # labels are no longer "integer"

# have the labels match the real classification of the flowers:
labels_colors(dend_iris) <-
   rainbow_hcl(3)[sort_levels_values(
      as.numeric(iris[,5])[order.dendrogram(dend_iris)]
   )]

# We'll add the flower type
labels(dend_iris) <- paste(as.character(iris[,5])[order.dendrogram(dend_iris)],
                           "(",labels(dend_iris),")", 
                           sep = "")

dend_iris <- hang.dendrogram(dend_iris,hang_height=0.1)

# reduce the size of the labels:
dend_iris <- assign_values_to_leaves_nodePar(dend_iris, 0.5, "lab.cex")

par(mar = c(3,3,3,7))
plot(dend_iris, 
     main = "Clustered Iris dataset
     (the labels give the true flower species)", 
     horiz =  TRUE,  nodePar = list(cex = .007))
legend("topleft", legend = iris_species, fill = rainbow_hcl(3))

@

This simple visualization easily demonstrates how the separation of the Hierarchical clustering is very good with the "setosa" species, but misses in labeling many "versicolor" species as "virginica".

The hanging of the tree also helps to locate extreme observations. For example, we can see that observation "virginica (107)" is not very similar to the Versicolor species, but still, it is among them. Also, "Versicolor (71)" is too much "within" the Virginica bush, and it is a wonder why that is.  Of course, the Iris data set is very well known, and simpler pairs plot often help to locate such problems, yet - dendrogram trees (with all of their limitations) can help gain insights for very high-dimensional data where a simple pairs plot is not possible.

Here is the similar pairs plot. Notice the filled red and green dots, corresponding with the extreme observations we have noticed in the dendrogram. Petal.Length vs Petal.Width gives the best example of why the green dot is an outlier. Whereas most plots show why the red dot is an outlier. There are of course other outliers, and a problem with classification, which we will not go further into.

<<iris_colored_pairs_plot, fig.height = 9, fig.width=9>>=
library(colorspace)

species_col <- rev(rainbow_hcl(3))[as.numeric(iris[,5])]
# species_col[c(107,71)] <- "red" # highlight the two extreme cases we mentioned
species_pch <- rep(1, length(species_col))
species_pch[c(107,71)] <- 19 # highlight the two extreme cases we mentioned

pairs(iris[,-5],
   col = species_col, pch=species_pch)


@






\section{Tanglegrams - visually comparing two trees side-by-side}

\subsection{Tanglegram visualization}

A tanglegram plot gives two dendrogram (with the same set of labels), one facing the other, and having their labels connected by lines. Tanglegram can be used for visually comparing two methods of Hierarchical clustering, and are sometimes used in biology when comparing two phylogenetic trees.

%% add references!

Here is an example of creating a tanglegram using \pkg{dendextend}:


<<first_tanglegram, fig.keep='high', fig.height = 19, fig.width=19>>=

hc1 <- hclust(dist(iris[,-5]), "com")
hc2 <- hclust(dist(iris[,-5]), "single")
dend1 <- as.dendrogram(hc1)
dend2 <- as.dendrogram(hc2)
tanglegram(dend1 , dend2, lab.cex = .5, edge.lwd = 1, margin_inner= 3, type = "r",
 center = TRUE, k_branches = 3)

@



Notice that since every manipulation of the trees require going through all of their nodes, it might be better (when comparing large trees), to do all of the manipulations upfront, and only then plot the tanglegram.

We can also notice the mess of tangled lines of the two trees, a mess we wish to untangle.

\subsection{Measuring Entanglement}

When comparing two trees via a tanglegram, we can use the \code{entanglement} function in order to measure how much the two trees are "aligned".

Entanglement is measured by giving the left tree's labels the values of 1 till tree size, and than match these numbers with the right tree. Now, entanglement is the L norm distance between these two vectors.
That is, we take the sum of the absolute difference (each one in the power of L). e.g: \code{sum(abs(x-y)**L)}.
And this is divided by the "worst case" entanglement level (e.g: when the right tree is the complete reverse of the left tree).

L tells us which penalty level we are at (L0, L1, L2, partial L's etc).  L>1 means that we give a big penalty for sharp angles.  While L->0 means that any time something is not a straight horizontal line, it gets a large penalty If L=0.1 it means that we much prefer straight lines over non straight lines


For example:

<<>>=

hc1 <- hclust(dist(iris[,-5]), "com")
hc2 <- hclust(dist(iris[,-5]), "single")
dend1 <- as.dendrogram(hc1)
dend2 <- as.dendrogram(hc2)
dend1 <- color_branches(dend1, 3)
# dend2 <- color_branches(dend2, 3) # colors will not match nicely
labels(dend2) <- as.character(labels(dend2))

library(colorspace)

col_lines_by_left_groups <- rainbow_hcl(3)[
   cutree(dend1, 3, order_clusters_as_data=FALSE)]
tanglegram(dend1 , dend2, color_lines=col_lines_by_left_groups,
           main = paste("Entanglement =", round(entanglement(dend1 , dend2), 2)))

@

And here is the entanglement of a tiny bit prettier tanglegram:

<<>>=

s_dend1 <- sort(dend1)
s_dend2 <- sort(dend2)

# s_dend1 <- color_branches(s_dend1, 3) # If I don't do this again
                  # I will get different colors
col_lines_by_left_groups_sorted <- col_lines_by_left_groups[match(labels(s_dend1), labels(dend1))]
tanglegram(s_dend1 , s_dend2, color_lines = col_lines_by_left_groups_sorted,
           main = paste("Entanglement =", round(entanglement(s_dend1 , s_dend2), 2)))

@



\subsection{Finding an optimal rotation}

\subsubsection{Random search}


Finding an optimal rotation for the tanglegram of two dendrogram is a hard problem.
%% ref here.

This problem is also harder for larger trees, so let us pick a tree from only 30 flowers, and look at comparing two clustering methods, complete and single:


<<>>=

set.seed(51324626)
ss <- sample(1:150, size=30)
hc1 <- hclust(dist(iris[ss,-5]), "com")
hc2 <- hclust(dist(iris[ss,-5]), "single")
dend1 <- as.dendrogram(hc1)
dend2 <- as.dendrogram(hc2)
dend1 <- color_branches(dend1, 3)
# dend2 <- color_branches(dend2, 3) # colors will not match nicely
labels(dend2) <- as.character(labels(dend2))

library(colorspace)

col_lines_by_left_groups <- rainbow_hcl(3)[
   cutree(dend1, 3, order_clusters_as_data=FALSE)]
tanglegram(dend1 , dend2, color_lines=col_lines_by_left_groups,
           main = paste("Entanglement =", round(entanglement(dend1 , dend2), 2)))

@

One solution for improving the tanglegram would be to randomly search the rotated tree space for a better solution.

For example:

<<>>=

set.seed(65168)
dend12 <- untangle_random_search(dend1, dend2, R=100)
tanglegram(dend12[[1]] , dend12[[2]], color_lines=col_lines_by_left_groups,
           main = paste("Entanglement =", round(entanglement(dend12[[1]] , dend12[[2]]), 2)))

@

We can see we already got something better. An advantage of the random search is the ability to create many many trees and compare them to find the best pair.


\subsubsection{A one-sided greedy search}

Let's use a greedy forward step wise rotation of the right tree, to see if we can find a better solution for comparing the two trees. Notice that this may take some time to run (the larger the tree, the longer it would take), but we can limit the search for smaller k's, and see what improvement that can bring us:


<<>>=

best_dend_heights_per_k <- heights_per_k.dendrogram(dend2)

dend2_2 <- untangle_step_rotate_1side(dend2, dend1,
               k_seq=2:3, best_dend_heights_per_k=best_dend_heights_per_k)[[1]]
# notice that here we are only using 
tanglegram(dend1 , dend2_2, color_lines=col_lines_by_left_groups,
           main = paste("Entanglement =", round(entanglement(dend1 , dend2_2), 2)))
entanglement(dend1 , dend2_2)

@


Let's try to go "all the way down" all possible k's:

<<>>=

dend2_3 <- untangle_step_rotate_1side(dend2, dend1,
                                      best_dend_heights_per_k=best_dend_heights_per_k)[[1]]
tanglegram(dend1 , dend2_3, color_lines=col_lines_by_left_groups,
           main = paste("Entanglement =", round(entanglement(dend1 , dend2_3), 2)))
entanglement(dend1 , dend2_3)


@

\subsubsection{Combining a one-sided greedy search with a random search}

As we can see, the random search actually found something better than the forward selection search. But now we can use the forward search on the trees we found in the random search:


<<>>=

dend2_4 <- untangle_step_rotate_1side(dend12[[2]], dend12[[1]])[[1]]
tanglegram(dend12[[1]] , dend2_4, color_lines=col_lines_by_left_groups,
           main = paste("Entanglement =", round(entanglement(dend12[[1]] , dend2_4), 2)))
entanglement(dend12[[1]] , dend2_4)


@

We see how this got us with a perfect solution. The trees look almost identical, but they are not (look at label 45 to see a leaf which is differently located between the two trees.). We can use the \code{k_branches} parameter for tanglegram, to help us see the difference between the two trees (notice labels 19 and 45). One could actually do an animation sequence, using various \code{k_branches} values in order to located the differences between the trees.

<<>>=
 
tanglegram(color_branches(dend12[[1]], col=1, k=1) , dend2_4, color_lines=col_lines_by_left_groups, k_branches=10, 
           main = paste("Entanglement =", round(entanglement(dend12[[1]] , dend2_4), 2)))

@


\subsubsection{A two-sided greedy search}

Sometimes, using just one-sided greedy algorithm is not enough. Also, it is probably best to combine the random search with the two sided greedy step-wise search:

<<untangle_step_rotate_2side_example>>=


dend1 <- as.dendrogram(hclust(dist(USArrests[1:20,])))
dend2 <- as.dendrogram(hclust(dist(USArrests[1:20,]), method = "single"))
set.seed(3525)
dend2 <- shuffle(dend2)
tanglegram(dend1,dend2, margin_inner=6.5)
entanglement(dend1,dend2, L = 2) # 0.79

dend2_corrected <- untangle_step_rotate_1side(dend2, dend1)[[1]]
tanglegram(dend1,dend2_corrected, margin_inner=6.5) # Good.
entanglement(dend1,dend2_corrected, L = 2) # 0.0067
# it is better, but not perfect. Can we improve it?

dend12_corrected <- untangle_step_rotate_2side(dend1, dend2)
tanglegram(dend12_corrected[[1]],dend12_corrected[[2]], margin_inner=6.5) # Better...
entanglement(dend12_corrected[[1]],dend12_corrected[[2]], L=2) # 0.0045


# best combination:
dend12_corrected_1 <- untangle_random_search(dend1, dend2)
dend12_corrected_2 <- untangle_step_rotate_2side(dend12_corrected_1[[1]],dend12_corrected_1[[2]])
tanglegram(dend12_corrected_2[[1]],dend12_corrected_2[[2]], margin_inner=6.5) # Better...
entanglement(dend12_corrected_2[[1]],dend12_corrected_2[[2]], L=2) # 0 - PERFECT.

# using rank_branches and k_branches, combined with type, center, and xlim - 
# helps to see various topological differences between the two trees:
tanglegram(dend12_corrected_2[[1]],
           dend12_corrected_2[[2]],
           k_branches = 7, rank_branches = TRUE,
           margin_inner=6.5, type = "t", center = TRUE,
           xlim = c(8,0)) # Much Better...


# using "hang=TRUE" also helps:
tanglegram(dend12_corrected_2[[1]],
           dend12_corrected_2[[2]],
           k_branches = 7, 
           rank_branches = TRUE, hang = TRUE,
           margin_inner=6.5, type = "r", center = TRUE,
           xlim = c(8,0)
           ) # Also Better... 

@




\section{Comparing two trees - statistics and inference}

\subsection{Baker's Gamma Index}

Baker's Gamma Index \citep{baker1974stability} is a measure of association (similarity) 
between two trees of Hierarchical clustering (dendrograms). It is defined as the rank correlation between the stages at which pairs of objects combine in each of the two trees.

Or more detailed: It is calculated by taking two items, and see what is the highest
possible level of k (number of cluster groups created when cutting the tree)
for which the two item still belongs to the same tree. That k is returned, 
and the same is done for these two items for the second tree.
There are n over 2 combinations of such pairs of items from the items in 
the tree, and all of these numbers are calculated for each of the two trees. 
Then, these two sets of numbers (a set for the items in each tree)
are paired according to the pairs of items compared, and a Spearman 
correlation is calculated.

The value can range between -1 to 1. With near 0 values meaning that
the two trees are not statistically similar.
For exact p-value one should use a permutation test. One such option
will be to permute over the labels of one tree many times, calculating 
the distribution under the null hypothesis (keeping the trees topologies
constant).

Notice that this measure is not affected by the height of a branch but only
of its relative position compared with other branches.


Here are a few examples:

<<cor_bakers_gamma_example_1>>=


set.seed(23235)
ss <- sample(1:150, 10 ) # we want to compare small trees
hc1 <- hclust(dist(iris[ss,-5]), "com")
hc2 <- hclust(dist(iris[ss,-5]), "single")
dend1 <- as.dendrogram(hc1)
dend2 <- as.dendrogram(hc2)
#    cutree(dend1)   

cor_bakers_gamma(hc1, hc2)
cor_bakers_gamma(dend1, dend2)

# dend1 <- match_order_by_labels(dend1, dend2) # if you are not sure
# cor_bakers_gamma(dend1, dend2, use_labels_not_values = FALSE)   

library(microbenchmark)
microbenchmark(
   with_labels = cor_bakers_gamma(dend1, dend2, try_cutree_hclust=FALSE)   ,
   with_values = cor_bakers_gamma(dend1, dend2, use_labels_not_values = FALSE, try_cutree_hclust=FALSE)   ,
   times=10
)

# The cor of a tree with itself is 1:
cor_bakers_gamma(dend1, dend1, use_labels_not_values = FALSE)   
cor_bakers_gamma(dend1, dend1, use_labels_not_values = TRUE)   
entanglement(dend1, dend1) # having a worse entanglement 
tanglegram(dend1, dend1) # having a worse entanglement 


# tree order has no effect on the correlation:
rev_dend1 <- rev(dend1)
cor_bakers_gamma(dend1, rev_dend1, use_labels_not_values = TRUE)   
entanglement(dend1, rev_dend1) # having a worse entanglement 
tanglegram(dend1, rev_dend1) # having a worse entanglement 

# But labels order does matter!!
dend1_mixed <- dend1
labels(dend1_mixed) <- rev(labels(dend1_mixed))
tanglegram(dend1, dend1_mixed)
entanglement(dend1, dend1_mixed) # having the worst entanglement 
# does NOT mean having the worst cor!
cor_bakers_gamma(dend1, dend1_mixed, use_labels_not_values = TRUE)   

set.seed(983597)
labels(dend1_mixed) <- sample(labels(dend1_mixed))
tanglegram(dend1, dend1_mixed)
entanglement(dend1, dend1_mixed) # having a worse entanglement 
cor_bakers_gamma(dend1, dend1_mixed, use_labels_not_values = TRUE)   


@


Since the observations creating the Baker's Gamma Index of such a measure are correlated, we need to perform a permutation test for the calculation of the statistical significance of the index. Let's look at the distribution of Baker's Gamma Index under the null hypothesis (assuming fixed tree topologies). This will be different for different tree structures and sizes. Here are the results when the compared tree is itself (after shuffling its own labels), and when comparing tree 1 to the shuffled tree 2:



<<cor_bakers_gamma_simulation_1>>=


set.seed(23235)
ss <- sample(1:150, 10 ) # we want to compare small trees
hc1 <- hclust(dist(iris[ss,-5]), "com")
hc2 <- hclust(dist(iris[ss,-5]), "single")
dend1 <- as.dendrogram(hc1)
dend2 <- as.dendrogram(hc2)
#    cutree(dend1)   

the_cor <- cor_bakers_gamma(dend1, dend1)
the_cor

R <- 1000
cor_bakers_gamma_results <- numeric(R)
dend_mixed <- dend1
for(i in 1:R) {
   dend_mixed <- sample.dendrogram(dend_mixed, replace = FALSE)
   cor_bakers_gamma_results[i] <- cor_bakers_gamma(dend1, dend_mixed)
}
plot(density(cor_bakers_gamma_results),
     main = "Baker's gamma distribution under H0",
     xlim = c(-1,1))
abline(v = 0, lty = 2)
abline(v = the_cor, lty = 2, col = 2)
title(sub = paste("One sided p-value =",  round(sum(the_cor < cor_bakers_gamma_results)/ R, 4)))

@


<<cor_bakers_gamma_simulation_2>>=


set.seed(23235)
ss <- sample(1:150, 10 ) # we want to compare small trees
hc1 <- hclust(dist(iris[ss,-5]), "com")
hc2 <- hclust(dist(iris[ss,-5]), "single")
dend1 <- as.dendrogram(hc1)
dend2 <- as.dendrogram(hc2)
#    cutree(dend1)   

the_cor <- cor_bakers_gamma(dend1, dend2)
the_cor

R <- 1000
cor_bakers_gamma_results <- numeric(R)
dend_mixed <- dend2
for(i in 1:R) {
   dend_mixed <- sample.dendrogram(dend_mixed, replace = FALSE)
   cor_bakers_gamma_results[i] <- cor_bakers_gamma(dend1, dend_mixed)
}
plot(density(cor_bakers_gamma_results),
     main = "Baker's gamma distribution under H0",
     xlim = c(-1,1))
abline(v = 0, lty = 2)
abline(v = the_cor, lty = 2, col = 2)
title(sub = paste("One sided p-value =",  round(sum(the_cor < cor_bakers_gamma_results)/ R, 4)))

@


And lastly, let us look at a simulation were labels of both trees are shuffled:


<<cor_bakers_gamma_simulation_3>>=


set.seed(23235)
ss <- sample(1:150, 10 ) # we want to compare small trees
hc1 <- hclust(dist(iris[ss,-5]), "com")
hc2 <- hclust(dist(iris[ss,-5]), "single")
dend1 <- as.dendrogram(hc1)
dend2 <- as.dendrogram(hc2)
#    cutree(dend1)   

the_cor <- cor_bakers_gamma(dend1, dend2)
the_cor

R <- 1000
cor_bakers_gamma_results <- numeric(R)
dend_mixed1 <- dend1
dend_mixed2 <- dend2
for(i in 1:R) {
   dend_mixed1 <- sample.dendrogram(dend_mixed1, replace = FALSE)
   dend_mixed2 <- sample.dendrogram(dend_mixed2, replace = FALSE)
   cor_bakers_gamma_results[i] <- cor_bakers_gamma(dend_mixed1, dend_mixed2)
}
plot(density(cor_bakers_gamma_results),
     main = "Baker's gamma distribution under H0",
     xlim = c(-1,1))
abline(v = 0, lty = 2)
abline(v = the_cor, lty = 2, col = 2)
title(sub = paste("One sided p-value =",  round(sum(the_cor < cor_bakers_gamma_results)/ R, 4)))

@

We can also calculate a bootstrap confidence interval using the \code{sample.dendrogram} function. This function can be very slow for larger trees, so make sure you use if carefully:

<<cor_bakers_gamma_simulation_CI_4>>=

set.seed(312356)
ss <- sample(1:150, 10 ) # we want to compare small trees
hc1 <- hclust(dist(iris[ss,-5]), "com")
hc2 <- hclust(dist(iris[ss,-5]), "single")
dend1 <- as.dendrogram(hc1)
dend2 <- as.dendrogram(hc2)
# tanglegram(dend1, dend2)
#    cutree(dend1)   

R <- 1000
dend1_labels <- labels(dend1)
dend2_labels <- labels(dend2)
cor_bakers_gamma_results <- numeric(R)
for(i in 1:R) {
   sampled_labels <- sample(dend1_labels, replace = TRUE)
   # members needs to be fixed since it will be later used in nleaves
   dend_mixed1 <- sample.dendrogram(dend1, 
                                    dend_labels=dend1_labels,
                                    fix_members=TRUE,fix_order=TRUE,fix_midpoint=FALSE,
                                    replace = TRUE, sampled_labels=sampled_labels
                                      )
   dend_mixed2 <- sample.dendrogram(dend2, dend_labels=dend2_labels,
                                    fix_members=TRUE,fix_order=TRUE,fix_midpoint=FALSE,
                                    replace = TRUE, sampled_labels=sampled_labels
                                      )                                    
   cor_bakers_gamma_results[i] <- cor_bakers_gamma(dend_mixed1, dend_mixed2, warn = FALSE)
}


# here is the tanglegram
tanglegram(dend1, dend2)
# And here is the tanglegram for one sample of our trees:
dend_mixed1 <- rank_order.dendrogram(dend_mixed1)
dend_mixed2 <- rank_order.dendrogram(dend_mixed2)
dend_mixed1 <- fix_members_attr.dendrogram(dend_mixed1)
dend_mixed2 <- fix_members_attr.dendrogram(dend_mixed2)
tanglegram(dend_mixed1, dend_mixed2)
cor_bakers_gamma(dend_mixed1, dend_mixed2, warn = FALSE)


CI95 <- quantile(cor_bakers_gamma_results, probs=c(.025,.975))
CI95
par(mfrow = c(1,1))
plot(density(cor_bakers_gamma_results),
     main = "Baker's gamma bootstrap distribution",
     xlim = c(-1,1))
abline(v = CI95, lty = 2, col = 3)
abline(v = cor_bakers_gamma(dend1, dend2), lty = 2, col = 2)
legend("topleft", legend =c("95% CI", "Baker's Gamma Index"), fill = c(3,2))

@

We can see that in our case, the non-parametric bootstrap confidence-intervals reassures us that the correlation is significantly different than 0 (thanks to the confidence-intervals duality with rejection regions). 




\subsection{Cophenetic correlation}

The cophenetic distance between two observations that have been clustered is defined to be the inter-group dissimilarity at which the two observations are first combined into a single cluster. This distance has many ties and restrictions. The cophenetic correlation \citep{sokal1962comparison} is the correlation between two cophenetic distance matrices of two trees.

The value can range between -1 to 1. With near 0 values meaning that the two trees are not statistically similar. For exact p-value one should result to a permutation test. One such option will be to permute over the labels of one tree many times, and calculating the distribution under the null hypothesis (keeping the trees topologies constant).

Here is a simple example:

<<cor_cophenetic_example_1>>=



set.seed(23235)
ss <- sample(1:150, 10 )
hc1 <- hclust(dist(iris[ss,-5]), "com")
hc2 <- hclust(dist(iris[ss,-5]), "single")
dend1 <- as.dendrogram(hc1)
dend2 <- as.dendrogram(hc2)
#    cutree(dend1)   

# cophenetic(hc1)
# cophenetic(hc2)
# # notice how the dist matrix for the dendrograms have different orders:
# cophenetic(dend1)
# cophenetic(dend2)

cor(cophenetic(hc1), cophenetic(hc2)) # 0.874
cor(cophenetic(dend1), cophenetic(dend2))  # 0.16
# the difference is becasue the order of the distance table in the case of
# stats:::cophenetic.dendrogram will change between dendrograms!

# However, this is consistant (since I force-sort the rows/columns): 
cor_cophenetic(hc1, hc2)
cor_cophenetic(dend1, dend2)

# we can also use different cor methods (almost the same result though): 
cor_cophenetic(hc1, hc2, method = "spearman") # 0.8456014
cor_cophenetic(dend1, dend2, method = "spearman") # 


# cophenetic correlation is about 10 times (!) faster than bakers_gamma cor:
library(microbenchmark)
microbenchmark(
   cor_bakers_gamma = cor_bakers_gamma(dend1, dend2, try_cutree_hclust=FALSE),
   cor_cophenetic = cor_cophenetic(dend1, dend2)   ,
   times=10
)

# but only because of the cutree for dendrogram. When allowing hclust cutree
# it is only about twice as fast:
microbenchmark(
   cor_bakers_gamma = cor_bakers_gamma(dend1, dend2, try_cutree_hclust=TRUE),
   cor_cophenetic = cor_cophenetic(dend1, dend2)   ,
   times=10
)

@

An example of a permutation test:

<<cor_cophenetic_simulation_2>>=


set.seed(23235)
ss <- sample(1:150, 10 ) # we want to compare small trees
hc1 <- hclust(dist(iris[ss,-5]), "com")
hc2 <- hclust(dist(iris[ss,-5]), "single")
dend1 <- as.dendrogram(hc1)
dend2 <- as.dendrogram(hc2)
#    cutree(dend1)   

the_cor <- cor_cophenetic(dend1, dend2)
the_cor

R <- 1000
cor_cophenetic_results <- numeric(R)
dend_mixed1 <- dend1
dend_mixed2 <- dend2
for(i in 1:R) {
   dend_mixed1 <- sample.dendrogram(dend_mixed1, replace = FALSE)
   dend_mixed2 <- sample.dendrogram(dend_mixed2, replace = FALSE)
   cor_cophenetic_results[i] <- cor_cophenetic(dend_mixed1, dend_mixed2)
}
plot(density(cor_cophenetic_results),
main = "Cophenetic correlation distribution under H0",
     xlim = c(-1,1))
abline(v = 0, lty = 2)
abline(v = the_cor, lty = 2, col = 2)
title(sub = paste("One sided p-value =",  round(sum(the_cor < cor_cophenetic_results)/ R, 4)))

@



An example of a bootstrap CI (with method="pearson"):


<<cor_cophenetic_simulation_CI_3>>=

set.seed(312356)
ss <- sample(1:150, 10 ) # we want to compare small trees
hc1 <- hclust(dist(iris[ss,-5]), "com")
hc2 <- hclust(dist(iris[ss,-5]), "single")
dend1 <- as.dendrogram(hc1)
dend2 <- as.dendrogram(hc2)
# tanglegram(dend1, dend2)
#    cutree(dend1)   

R <- 1000
dend1_labels <- labels(dend1)
dend2_labels <- labels(dend2)
cor_cophenetic_results <- numeric(R)
for(i in 1:R) {
   sampled_labels <- sample(dend1_labels, replace = TRUE)
   # members needs to be fixed since it will be later used in nleaves
   dend_mixed1 <- sample.dendrogram(dend1, 
                                    dend_labels=dend1_labels,
                                    fix_members=TRUE,fix_order=TRUE,fix_midpoint=FALSE,
                                    replace = TRUE, sampled_labels=sampled_labels
                                      )
   dend_mixed2 <- sample.dendrogram(dend2, dend_labels=dend2_labels,
                                    fix_members=TRUE,fix_order=TRUE,fix_midpoint=FALSE,
                                    replace = TRUE, sampled_labels=sampled_labels
                                      )                                    
   cor_cophenetic_results[i] <- cor_cophenetic(dend_mixed1, dend_mixed2, warn = FALSE)
}


# here is the tanglegram
# tanglegram(dend1, dend2)
# And here is the tanglegram for one sample of our trees:
dend_mixed1 <- rank_order.dendrogram(dend_mixed1)
dend_mixed2 <- rank_order.dendrogram(dend_mixed2)
dend_mixed1 <- fix_members_attr.dendrogram(dend_mixed1)
dend_mixed2 <- fix_members_attr.dendrogram(dend_mixed2)
# tanglegram(dend_mixed1, dend_mixed2)
cor_cophenetic(dend_mixed1, dend_mixed2, warn = FALSE)


CI95 <- quantile(cor_cophenetic_results, probs=c(.025,.975))
CI95
par(mfrow = c(1,1))
plot(density(cor_cophenetic_results),
     main = "Cophenetic correlation - bootstrap distribution",
     xlim = c(-1,1))
abline(v = CI95, lty = 2, col = 3)
abline(v = cor_cophenetic(dend1, dend2), lty = 2, col = 2)
legend("topleft", legend =c("95% CI", "Cophenetic correlation"), fill = c(3,2))

@


An example of a bootstrap CI (with method="spearman"):


<<cor_cophenetic_simulation_CI_4>>=

set.seed(312356)
ss <- sample(1:150, 10 ) # we want to compare small trees
hc1 <- hclust(dist(iris[ss,-5]), "com")
hc2 <- hclust(dist(iris[ss,-5]), "single")
dend1 <- as.dendrogram(hc1)
dend2 <- as.dendrogram(hc2)
# tanglegram(dend1, dend2)
#    cutree(dend1)   

R <- 1000
dend1_labels <- labels(dend1)
dend2_labels <- labels(dend2)
cor_cophenetic_results <- numeric(R)
for(i in 1:R) {
   sampled_labels <- sample(dend1_labels, replace = TRUE)
   # members needs to be fixed since it will be later used in nleaves
   dend_mixed1 <- sample.dendrogram(dend1, 
                                    dend_labels=dend1_labels,
                                    fix_members=TRUE,fix_order=TRUE,fix_midpoint=FALSE,
                                    replace = TRUE, sampled_labels=sampled_labels
                                      )
   dend_mixed2 <- sample.dendrogram(dend2, dend_labels=dend2_labels,
                                    fix_members=TRUE,fix_order=TRUE,fix_midpoint=FALSE,
                                    replace = TRUE, sampled_labels=sampled_labels
                                      )                                    
   cor_cophenetic_results[i] <- cor_cophenetic(dend_mixed1, dend_mixed2, warn = FALSE, method="spearman")
}


# here is the tanglegram
# tanglegram(dend1, dend2)
# And here is the tanglegram for one sample of our trees:
dend_mixed1 <- rank_order.dendrogram(dend_mixed1)
dend_mixed2 <- rank_order.dendrogram(dend_mixed2)
dend_mixed1 <- fix_members_attr.dendrogram(dend_mixed1)
dend_mixed2 <- fix_members_attr.dendrogram(dend_mixed2)
# tanglegram(dend_mixed1, dend_mixed2)
cor_cophenetic(dend_mixed1, dend_mixed2, warn = FALSE, method="spearman")


CI95 <- quantile(cor_cophenetic_results, probs=c(.025,.975))
CI95
par(mfrow = c(1,1))
plot(density(cor_cophenetic_results),
     main = "Cophenetic correlation - bootstrap distribution",
     xlim = c(-1,1))
abline(v = CI95, lty = 2, col = 3)
abline(v = cor_cophenetic(dend1, dend2, method="spearman"), lty = 2, col = 2)
legend("topleft", legend =c("95% CI", "Cophenetic correlation"), fill = c(3,2))

@




\subsection{The Fowlkes-Mallows Index and the Bk plot}

\subsubsection{The Fowlkes-Mallows Index}

The Fowlkes-Mallows Index \citep{fowlkes1983method} (FM Index, or Bk) is a measure of similarity between two clusterings. The FM index ranges from 0 to 1, a higher value indicates a greater similarity between the two clusters.

The \pkg{dendextend} package allows the calculation of FM-Index, its expectancy and variance under the null hypothesis, and a creation of permutations of the FM-Index under $H_0$. Thanks to the \pkg{profdpm} package \citep{CRAN:profdpm}, we have another example of calculating the FM (though it does not offer the expectancy and variance under $H_0$):

<<FM_index_examples_1>>=

ss <- TRUE # sample(1:150, 10 )
hc1 <- hclust(dist(iris[ss,-5]), "com")
hc2 <- hclust(dist(iris[ss,-5]), "single")

# FM index of a cluster with himself is 1:
FM_index(cutree(hc1, k=3), cutree(hc1, k=3))
# FM index of two clusterings:
FM_index(cutree(hc1, k=3), cutree(hc2, k=3)) 
# we got a value far above the expected under H0
         
# Using the R code:
FM_index_R(cutree(hc1, k=3), cutree(hc2, k=3))
# Or wrapping the code from profdpm: (notice the NA's)
FM_index_profdpm(cutree(hc1, k=3), cutree(hc2, k=3))



@

The distribution of FM is interesting for medium sized k (25), we can test it using a permutation test:

<<FM_permutation_example_1>>=

set.seed(23235)
ss <- TRUE # sample(1:150, 10 )
hc1 <- hclust(dist(iris[ss,-5]), "com")
hc2 <- hclust(dist(iris[ss,-5]), "single")
# dend1 <- as.dendrogram(hc1)
# dend2 <- as.dendrogram(hc2)
#    cutree(dend1)   

# # small k
# A1_clusters <- cutree(hc1, k=3) # will give a right tailed distribution
# # large k
# A1_clusters <- cutree(hc1, k=50) # will give a discrete distribution
# "medium" k
A1_clusters <- cutree(hc1, k=25) # gives almost the normal distribution!
A2_clusters <- A1_clusters

R <- 10000
set.seed(414130)
FM_index_H0 <- replicate(R, FM_index_permutation(A1_clusters, A2_clusters)) # can take 10 sec
plot(density(FM_index_H0), main = "FM Index distribution under H0\n (10000 permutation)")
abline(v = mean(FM_index_H0), col = 1, lty = 2)
# The permutation distribution is with a heavy right tail:
# library(psych)
# skew(FM_index_H0) # 1.254
# kurtosi(FM_index_H0) # 2.5427

mean(FM_index_H0); var(FM_index_H0)
the_FM_index <- FM_index(A1_clusters, A2_clusters)
the_FM_index
our_dnorm <- function(x) {
   dnorm(x, mean = attr(the_FM_index, "E_FM"), 
         sd = sqrt(attr(the_FM_index, "V_FM")))
}
# our_dnorm(0.35)
curve(our_dnorm,
      col = 4,
      from = -1,to=1,n=R,add = TRUE)
abline(v = attr(the_FM_index, "E_FM"), col = 4, lty = 2)

legend("topright", legend = c("asymptotic", "permutation"), fill = c(4,1))

@

It is interesting to compare how the two distributions diverge when K (3) is smaller:


<<FM_permutation_example_2, echo=FALSE>>=

set.seed(23235)
ss <- TRUE # sample(1:150, 10 )
hc1 <- hclust(dist(iris[ss,-5]), "com")
hc2 <- hclust(dist(iris[ss,-5]), "single")
# dend1 <- as.dendrogram(hc1)
# dend2 <- as.dendrogram(hc2)
#    cutree(dend1)   

# small k
A1_clusters <- cutree(hc1, k=3) # will give a right tailed distribution
# # large k
# A1_clusters <- cutree(hc1, k=50) # will give a discrete distribution
# "medium" k
# A1_clusters <- cutree(hc1, k=25) # gives almost the normal distribution!
A2_clusters <- A1_clusters

R <- 10000
set.seed(414130)
FM_index_H0 <- replicate(R, FM_index_permutation(A1_clusters, A2_clusters)) # can take 10 sec
plot(density(FM_index_H0), main = "FM Index distribution under H0\n (10000 permutation)")
abline(v = mean(FM_index_H0), col = 1, lty = 2)
# The permutation distribution is with a heavy right tail:
# library(psych)
# skew(FM_index_H0) # 1.254
# kurtosi(FM_index_H0) # 2.5427

mean(FM_index_H0); var(FM_index_H0)
the_FM_index <- FM_index(A1_clusters, A2_clusters)
the_FM_index
our_dnorm <- function(x) {
   dnorm(x, mean = attr(the_FM_index, "E_FM"), 
         sd = sqrt(attr(the_FM_index, "V_FM")))
}
# our_dnorm(0.35)
curve(our_dnorm,
      col = 4,
      from = -1,to=1,n=R,add = TRUE)
abline(v = attr(the_FM_index, "E_FM"), col = 4, lty = 2)

legend("topright", legend = c("asymptotic", "permutation"), fill = c(4,1))

@

Or of how it will look when K (80) is large (and the distribution becomes discrete):


<<FM_permutation_example_3, echo=FALSE>>=

set.seed(23235)
ss <- TRUE # sample(1:150, 10 )
hc1 <- hclust(dist(iris[ss,-5]), "com")
hc2 <- hclust(dist(iris[ss,-5]), "single")
# dend1 <- as.dendrogram(hc1)
# dend2 <- as.dendrogram(hc2)
#    cutree(dend1)   

# small k
# A1_clusters <- cutree(hc1, k=3) # will give a right tailed distribution
# # large k
A1_clusters <- cutree(hc1, k=80) # will give a discrete distribution
# "medium" k
# A1_clusters <- cutree(hc1, k=25) # gives almost the normal distribution!
A2_clusters <- A1_clusters

R <- 10000
set.seed(414130)
FM_index_H0 <- replicate(R, FM_index_permutation(A1_clusters, A2_clusters)) # can take 10 sec
plot(density(FM_index_H0), main = "FM Index distribution under H0\n (10000 permutation)")
abline(v = mean(FM_index_H0), col = 1, lty = 2)
# The permutation distribution is with a heavy right tail:
# library(psych)
# skew(FM_index_H0) # 1.254
# kurtosi(FM_index_H0) # 2.5427

mean(FM_index_H0); var(FM_index_H0)
the_FM_index <- FM_index(A1_clusters, A2_clusters)
the_FM_index
our_dnorm <- function(x) {
   dnorm(x, mean = attr(the_FM_index, "E_FM"), 
         sd = sqrt(attr(the_FM_index, "V_FM")))
}
# our_dnorm(0.35)
curve(our_dnorm,
      col = 4,
      from = -1,to=1,n=R,add = TRUE)
abline(v = attr(the_FM_index, "E_FM"), col = 4, lty = 2)

legend("topright", legend = c("asymptotic", "permutation"), fill = c(4,1))

@

\subsubsection{The Bk plot}


In the Bk method we calculate the FM Index (Bk) for each k (k=2,3,...,n-1) number of clusters, giving the association between the two trees when each is cut to have k groups. The similarity between two hierarchical clustering dendrograms, can be investigated, using the (k,Bk) plot: For every level of splitting of the two dendrograms which produces k clusters in each tree, the plot shows the number Bk, and therefore enables the investigation of potential nuances in the structure of similarity. The Bk measures the number of pairs of items which are in the same cluster in both dendrograms, one of the clusters in one of the trees and one of the clusters in the other tree, divided by the geometric mean of the number of pairs of items which are in the same cluster in each tree. Namely, ${a_{uv}} = 1\left( {or{\rm{ }}{{\rm{b}}_{uv}} = 1} \right)$ if the items u and v are in the same cluster in the first tree (second tree), when it is cut so to give k clusters, and otherwise 0:

\[{FM_k} = {B_k} = \frac{{\sum\limits_{}^{} {{a_{uv}}{b_{uv}}} }}{{\sqrt {\sum\limits_{}^{} {{a_{uv}}} \sum\limits_{}^{} {{b_{uv}}} } }}\]

The Bk measure can be plotted for every value of k (except k=n) in order to create the "(k,Bk) plot".  The plot compares the similarity of the two trees for different cuts. The mean and variance of Bk, under the null hypothesis (that the two trees are not "similar"), and under the assumption that the margins of the matching matrix are fixed, are given in Fowlkes and Mallows \citep{fowlkes1983method}. They allow making inference on whether the results obtained are different from what would have been expected under the null hypothesis (of now particular order of the trees' labels).

The \code{Bk} and the \code{Bk_plot} functions allow the calculation of the FM-Index for a range of k values on two trees. Here are examples:

<<Bk_examples>>=
   
set.seed(23235)
ss <- TRUE # sample(1:150, 30 ) # TRUE #
hc1 <- hclust(dist(iris[ss,-5]), "com")
hc2 <- hclust(dist(iris[ss,-5]), "single")
dend1 <- as.dendrogram(hc1)
dend2 <- as.dendrogram(hc2)
#    cutree(tree1)   

# It works the same for hclust and dendrograms:
Bk(hc1, hc2, k = 3)
Bk(dend1, dend2, k = 3)

library(microbenchmark)
microbenchmark(
      Bk(hc1, hc2, k = 3),
      Bk(dend1, dend2, k = 3),
      times = 10
   ) # the "dend" method is much slower (since it relies less on C code).

# however, because the hc2 tree is actually with several branches/leaves of 
# the same height - actually the dendrogram object gives a more correct output!


@

The Bk plot:

<<Bk_plot_for_hclust_WRONG>>=
Bk_plot(hc1, hc2, main = "WRONG Bk plot \n(due to the way cutree works with ties in hclust)", warn = FALSE)
@

<<Bk_plot_for_dends_correct, warning=FALSE>>=
Bk_plot(dend1, dend2, main = "CORRECT Bk plot \n(based on dendrograms)")
@



% 
% A reminder tanglegram:
% 
% <<>>=
% set.seed(2542)
% dend12_corrected_1 <- untangle_random_search(dend1, dend2,R=10)
% dend12_corrected_2 <- untangle_step_rotate_2side(dend12_corrected_1[[1]],dend12_corrected_1[[2]])
% tanglegram(dend12_corrected_2[[1]],dend12_corrected_2[[2]], margin_inner=6.5) # Better...
% 
% @
% 







\section{dendextendRcpp - gaining speed with Rcpp}

Since dendrogram objects are often revised through the use of recursion, R often falls short when it comes to speed. In various function which are intended to run only once (such as \code{labels.color}), this does not bother us, and we are content at quickly writing the function with R and letting it handle many extreme cases.

However, some functions are intended to be used many times, and in such cases are well served to be handled with \proglang{C++}. Thanks the the \pkg{Rcpp} package (\cite{CRAN:Rcpp}, \cite{JSS:Rcpp}), we can comfortably extend several core functions of the dendextend package. These modifications are included in a separate add-on package called \pkg{dendextendRcpp} \citep{CRAN:dendextendRcpp} by Dirk Eddelbuettel, Romain Fran\c{c}ois and Tal Galili. \pkg{dendextendRcpp} is set to load automatically when \pkg{dendextend} loads, and its functions are set to properly override the R functions.

Here are a few benchmarks using the \pkg{microbenchmark} package \citep{CRAN:microbenchmark}.

For \code{labels.dendrogram}:

<<Rcpp_simu_labels_dendrogram>>=

dend <- as.dendrogram(hclust(dist(iris[,-5])))
labels(dend) <- as.character(labels(dend))

library(dendextendRcpp) # already loaded by default with dendextend
library(microbenchmark)
microbenchmark(
stats:::labels.dendrogram(dend),
dendextendRcpp::labels.dendrogram(dend)
   ) 
# Rcpp is ~34 times faster

@


For \code{get_branches_heights} (an essential function when using cutree with some k):

<<Rcpp_simu_get_branches_heights>>=

dend <- as.dendrogram(hclust(dist(iris[,-5])))
labels(dend) <- as.character(labels(dend))

library(microbenchmark)
library(dendextendRcpp)
microbenchmark(
   dendextendRcpp::dendextendRcpp_get_branches_heights(dend),
   old_get_branches_heights(dend,sort=F),
   times = 10)

# ~148 times faster! (for larger trees)

# Rcpp is ~90 times faster!

@

For \code{heights_per_k.dendrogram} (an essential function when using cutree with some k):

<<Rcpp_simu_heights_per_k>>=

library(microbenchmark)
library(dendextendRcpp)
# dend <- as.dendrogram(hclust(dist(iris[1:150,-5])))
dend <- as.dendrogram(hclust(dist(iris[1:30,-5])))
# dend <- as.dendrogram(hclust(dist(iris[1:3,-5])))
microbenchmark( 
   #    dendextendRcpp::heights_per_k.dendrogram(dend),
   dendextendRcpp::dendextendRcpp_heights_per_k.dendrogram(dend),
   dendextendRcpp::old_heights_per_k.dendrogram(dend),
   times = 10
)
# improvment is 10 times faster (in Rcpp) for a tree of size 3
# 76 times faster for a tree of size 30
# And:
# 134 times faster for a tree of size 150!!



@


For \code{cut_lower_fun} (an essential function when using cutree with some h):

<<Rcpp_simu_cut_lower_fun>>=

   # library(dendextend)
   library(dendextendRcpp)
   dend_big = as.dendrogram(hclust(dist(iris[1:150,-5])))
   library(microbenchmark)
   microbenchmark(old_cut_lower_fun(dend_big,.1),
                  dendextendRcpp::dendextendRcpp_cut_lower_fun(dend_big,.1),
                     times = 100)
   # about 7-15 times faster. It is faster the larger the tree is, and the lower h is.

@


% 
% 
% a short review of other approaches and give some historical
% background on the development of \pkg{dendextend}.
% 
% 
% Several examples are included to illustrate the functionality of \pkg{dendextend}. Many more examples are available within
% the package. % , both as explicit examples and as part of the numerous unit tests.
% %
% The \pkg{dendextend} package is available from the Comprehensive \proglang{R} Archive Network (CRAN)
% at \url{https://cran.r-project.org/package=dendextend}.
% 
% \makeatletter
% \if@nojss
%   This vignette will one day corresponds to a paper 
%   
% %   published in the \textsl{Journal of Statistical Software}. It is currently still identical to the published paper.  
%   
%   Over time, this vignette version may receive minor
%   updates. For citations, please use %the \cite{JSS:dendextend} or
%   % \cite{Eddelbuettel:2013:dendextend}; details are also provided in
%   \proglang{R} via \texttt{citation("dendextend")}.
% 
%   This version corresponds to \pkg{dendextend} version \Sexpr{dendextend.version} and was typeset on \Sexpr{now.date}.
% \fi
% \makeatother
% 

% \subsection{Historical context}
% \subsection{Related work}

%%% \cite - name and date in (),, \citep - (all in ())
% \cite{TempleLang:2009:RGCCTranslationUnit}, 

% \subsection[dendextend use cases]{\pkg{dendextend} use cases}
% \label{sec:classic_dendextend}

% \subsection[dendextend class hierarchy]{\pkg{dendextend} class hierarchy}
% \subsection{Derived classes}

% \subsection{Character vectors}

% \section[R and C++ data interchange]{\proglang{R} and \proglang{C++} data interchange}

% \subsection[C++ to R: wrap]{\proglang{C++} to \proglang{R}: \code{wrap}}
% \subsection[R to C++: as]{\proglang{R} to \proglang{C++}: \code{as}}

% The \citep command is used where the author name is to appear inside the parentheses alongside the date.
% \citep{Sanderson:2010:Armadillo}.


% \subsection{Implicit use of converters}

% \section{Function calls}
% \label{sec:functions}

% \section{Using code `inline'}
% \label{sec:inline}
% \code{update.packages()} 
% \footnote{This presumes a platform for which pre-built binaries are}
% \cite{CRAN:dendextend:Attributes} for more details.

% \section{Using Standard Template Library algorithms}

% \citep{Plauger+Et+Al:2000:STL}. 


% \section{Error handling}
% \subsection[C++ exceptions in R]{\proglang{C++} exceptions in \proglang{R}}
% \subsection[R errors in C++]{\proglang{R} errors in \proglang{C++}}


% \section{Performance comparison}
% \label{sec:perfcomp}



% %
% \begin{Code}
% ...
% \end{Code}
% %

% are summarized in Table~\ref{tab:benchmark} below.
% 
% \begin{table}[t]
%   \begin{center}
%     \begin{small}
%       \begin{tabular}{lrr}
%         \toprule
%         Implementation                    & Time in millisec. & Relative to \proglang{R} API \\
%         \cmidrule(r){2-3}
%         \proglang{R} API (as benchmark)             &  218       & \\
%         \pkg{dendextend} sugar                        &  145       & 0.67 \\
%         \code{NumericVector::iterator}    &  217       & 1.00 \\
%         \code{NumericVector::operator[]}  &  282       & 1.29 \\
%         %\code{dendextendVector<double>}         &  683       & 3.13 \\
%         \bottomrule
%       \end{tabular}
%     \end{small}
%     \caption{Run-time performance of the different convolution examples.}
%     \label{tab:benchmark}
%   \end{center}
% \end{table}
% 

% \section{On-going development}
% \label{sec:ongoing}

% \code{head},


\section{Summary}

The \pkg{dendextend} package presented in this paper greatly extends the available functionality of the dendrogram objects in \proglang{R}.

% compiled \proglang{C++} code with \proglang{R}.
% \pkg{dendextend} provides a \proglang{C++} class hierarchy which allows manipulation of \proglang{R} data structures in \proglang{C++}
% using member functions and operators directly related to the type
% of object being used, thereby reducing the level of expertise
% required to master the various functions and macros offered by the
% internal \proglang{R} API. The classes assume the entire
% responsibility of garbage collection of objects, relieving the
% programmer from book-keeping operations with the protection stack
% and enabling him/her to focus on the underlying problem.
% 
% Data interchange between \proglang{R} and \proglang{C++} code is performed by the \code{wrap()} and
% \code{as()} template functions. They allow the programmer to write logic in terms
% of \proglang{C++} data structures, and facilitate use of modern libraries such as the
% Standard Template Library (STL) and its containers and algorithms. The
% \code{wrap()} and \code{as()} template functions are extensible by
% design. They are also used either explicitly or implicitly throughout the API.
% By using only thin wrappers around \code{SEXP} objects and adopting \proglang{C++}
% idioms such as iterators, the footprint of the \pkg{dendextend} API
% is very lightweight, and does not incur a significant performance penalty.
% 
% The \pkg{dendextend} API offers opportunities to dramatically reduce the complexity
% of code, which should lower the initial cost of writing code and improve code readability, maintainability, and
% reuse---without incurring noticeable penalties in run-time performance.



\section*{Acknowledgments}

We are very thankful for code contributions and ideas by the R core team (especially Martin Maechler and Brian Ripley, but probably also others without our knowledge), Gavin Simpson, Gregory Jefferis
,
% Detailed comments and suggestions by editors as well as anonymous referees
% are gratefully acknowledged.  


\bibliography{dendextend-tutorial}

\vspace*{-0.35cm}




\section*{R Session Info}


<<sessionInfo, cache=FALSE>>=

Sys.Date()

sessionInfo()

@




\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:


%% library(knitr)
%% Sweave2knitr('vignettes\\dendextend-tutorial.rnw')
